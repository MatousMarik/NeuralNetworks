{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Multilayered Neural Networks\n",
    "Assignment [here](NNAssignment2_2022.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Weights initialization for a single neuron\n",
    "Expected value of the potential:\n",
    "$$\\text{E}\\{\\xi\\}=\\text{E}\\Biggl\\{\\sum_{i=1}^N w_ix_i\\Biggr\\} = \\sum_{i=1}^N \\text{E}\\{w_i\\} \\text{E}\\{x_i\\}$$\n",
    "since weights are independent of the input.\n",
    "From uniformly distributed $w_i$ in interval $\\langle -a, a \\rangle$ or $\\mu=0$ we have $\\text{E}\\{\\xi\\}=0$.\n",
    "\n",
    "Variance of the potential:\n",
    "$$\\sigma_\\xi^2 = \\text{E}\\{\\xi^2\\} - \\text{E}^2\\{\\xi\\}$$\n",
    "since expected value of the potential will be 0:\n",
    "$$\\sigma_\\xi^2 = \\text{E}\\Biggl\\{\\biggl(\\sum_{i=1}^N w_ix_i\\biggr)^2\\Biggr\\} - 0 = \\sum_{i,j=1}^N \\text{E}\\{(w_iw_jx_ix_j)\\}$$\n",
    "and from mutual independence:\n",
    "$$\\sigma_\\xi^2 = \\sum_{i=1}^N \\text{E}\\{(w_i)^2\\}\\text{E}\\{(x_i)^2\\}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since weights are random variables with zero mean and are uniformly distributed in $\\langle -a, a \\rangle$:\n",
    "$$\\text{E}\\{(w_i)^2\\} = \\int_{-a}^a w_i^2 \\frac{1}{2a}\\mathrm{d}w_i = \\left. \\frac{w_i^3}{6a} \\right\\rvert_{-a}^{a} = \\frac{a^2}{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know $x$ has normal probability distribution with $\\mu = 0$ and $\\sigma > 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we know variance formula:\n",
    "$$\\sigma_x^2 = \\text{E}\\{x^2\\} - \\text{E}^2{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From that we can derive:\n",
    "\n",
    "$$ \\text{E}\\{x^2\\} = \\sigma_x^2 + 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need to calculate:\n",
    "$$\\sigma_\\xi^2 = \\sum_{i=1}^N \\text{E}\\{(w_i)^2\\}\\text{E}\\{(x_i)^2\\} = 1$$\n",
    "since we require $\\sigma_\\xi = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From that:\n",
    "$$\\sigma_\\xi^2 = \\sum_{i=1}^N \\frac{a^2}{3}\\sigma_{x_i}^2 = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a^2\\frac{N\\sigma_x^2}{3} = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a = \\frac{1}{\\sigma_x}\\sqrt{\\frac{3}{N}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For std $A$:\n",
    "$$\\sqrt{a^2\\frac{N\\sigma_x^2}{3}} = A$$\n",
    "$$a = \\frac{A}{\\sigma_x}\\sqrt{\\frac{3}{N}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Manual design of a neural network for computing a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets say extended input to a layer is [x1, x2, 1] where 1 is is the extension for the bias.  \n",
    "Also lets say we use BigEndianity so 2 => 10, 1 => 01\n",
    "\n",
    "\n",
    "Then extended weight vectors for the input-hidden layers are: \n",
    "<pre>-7  5  \n",
    "-7  5\n",
    " 3 -7 </pre>\n",
    "\n",
    "And for hidden-output layer:\n",
    "<pre>-9 10  \n",
    " 5 10\n",
    " 4 -5</pre>\n",
    "\n",
    "I.e. biases/thresholds are the last rows and output_of_the_first_layer for vector [1, 0]\n",
    "will be sigmoid([-4, -2]).  \n",
    "    -4 = 1\\*-7 + 0\\*-7 + 1\\*3\n",
    "\n",
    "Then the final outputs will be:\n",
    "| Vector | Output |\n",
    "| ---: | ---: |\n",
    "| [0, 0] | [0.01026587, 0.98938538] |\n",
    "| [1, 0] | [0.98827385, 0.02587887] |\n",
    "| [0, 1] | [0.98827385, 0.02587887] |\n",
    "| [1, 1] | [0.99984357, 0.98929105] |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01026587 0.98938538]\n",
      "[0.98827385 0.02587887]\n",
      "[0.98827385 0.02587887]\n",
      "[0.99984357 0.98929105]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_w():\n",
    "    return [\n",
    "        np.array([[-7, 5], [-7, 5], [3, -7]], dtype=float),\n",
    "        np.array([[-9, 10], [5, 10], [4, -5]], dtype=float),\n",
    "    ]\n",
    "\n",
    "\n",
    "def sigmoid(ksi):\n",
    "    return 1 / (1 + np.exp(-ksi))\n",
    "\n",
    "w1, w2 = get_w()\n",
    "for inp in [[0, 0], [1, 0], [0, 1], [1, 1]]:\n",
    "    inp = np.array([*inp, 1])\n",
    "    h_out = np.dot(inp, w1)\n",
    "    h_out = sigmoid(h_out)\n",
    "    o_in = np.array([*h_out, 1])\n",
    "    o_out = np.dot(o_in, w2)\n",
    "    o_out = sigmoid(o_out)\n",
    "    print(o_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Weights update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New in-h weights\n",
      "[[ 1.40785247 -2.21943588]\n",
      " [ 0.19214753  0.91943588]\n",
      " [-0.30785247 -0.38056412]]\n",
      "New h-out weights\n",
      "[[ 1.90411386  0.83298221]\n",
      " [-1.25356135  0.92277813]\n",
      " [ 0.22939793 -0.68913215]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "lambda_ = 2.0\n",
    "\n",
    "def sigmoid2(ksi):\n",
    "    return 1 / (1 + np.exp(-lambda_ * ksi))\n",
    "\n",
    "w1 = np.array([[ 1.1, -2.2],\n",
    "[ 0.5, 0.9],\n",
    "[ 0.0, -0.4]])\n",
    "\n",
    "w2 = np.array([[ 2.0, 0.9],\n",
    "[-1.0, 1.1],\n",
    "[ 0.5, -0.5]])\n",
    "\n",
    "p = np.array([-1,1])\n",
    "d = np.array([0.2, 0.4])\n",
    "\n",
    "lr = 1.5\n",
    "\n",
    "# through first layer\n",
    "i0 = np.array([*p, 1.])\n",
    "h = np.dot(i0, w1)\n",
    "h_out = sigmoid(h)\n",
    "\n",
    "# through second layer\n",
    "i1 = np.array([*h_out, 1.])\n",
    "o = np.dot(i1, w2)\n",
    "out = sigmoid(o)\n",
    "\n",
    "error2 = d - out\n",
    "\n",
    "# backpropagation\n",
    "d2 = lambda_ * out * (1 - out) * error2\n",
    "w2 += lr * np.outer(i1, d2)\n",
    "\n",
    "error1 = d2 @ np.transpose(w2[:-1])\n",
    "d1 = lambda_ * h_out * (1 - h_out) * error1\n",
    "\n",
    "w1 += lr * np.outer(i0, d1)\n",
    "\n",
    "print(\"New in-h weights\")\n",
    "print(w1)\n",
    "print(\"New h-out weights\")\n",
    "print(w2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
